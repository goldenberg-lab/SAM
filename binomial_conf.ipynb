{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power calculations for a binomial proportion\n",
    "\n",
    "## Background\n",
    "\n",
    "In an ideal statistical world no hypothesis test would be run before a [power analysis](https://en.wikipedia.org/wiki/Power_of_a_test) has been carried out to determine a reasonable [sample size](https://en.wikipedia.org/wiki/Sample_size_determination). Most researchers carrying out statistical hypothesis testing only focus on the type-I error: the probability of erreneously rejecting a null hypothesis. Since the null hypothesis is synonymous with the \"no effects\" regime, this amounts to controlling the number spurious discoveries. Sophisticated techniques have also been developed to control the type-I error under the problem of [multiple comaparisons](https://en.wikipedia.org/wiki/Multiple_comparisons_problem). This focus on type-I error leads to significant problem in academic research: inflated effect size estimates. Unfortunately, advanced statistical methods give researchers a false confidence that their \"significant\" discoveries are \"true\", in the sense that they are probably not *completely* spurious.  \n",
    "\n",
    "The power of the test is probality of rejecting the null when it is false. In the \"no effects\" regime this is equivalent to correctly concluding there is some real effect. Power is inversely related to effect size bias because results that are statistically significant go through a filter: only realized statisticals below a certain p-value are examined. If the power of a test is large, then the descrepancy between the distribution of the statistic conditional on statistically significance will be similar to its unconditional distribution.[[^1]] Generally speaking, a test that with a large power, say 80%, will have a fairly small effect size bias. \n",
    "\n",
    "Power analysis is by no means absent from empirical research. It is essential for grant funding applications in biomedical research and the design of clinical trials. I suspect that as statistics have moved towards \"big data\" and \"analytics\" the cultural emphasis on a well-designed statistical procedure has shifted to \"mining\" for hidden results. In such situations estimating the power is impossible because its not even clear what the hypothesis test is! Another reason power is less focused on is that it is harder to carry out. A researcher needs to make several assumptions that are normally not needed for calculating type-I errors including the estimated signal size and sometimes other nuissance parameters.\n",
    "\n",
    "This post is about how to calculate the number of samples that will be needed to obtain a specified power for a test of a binomial proportion. Anytime there is a binary outcome which is being measured in aggregate (between groups, systems, cities, etc) we can ask whether this proportion is different than some amount. For example is there a difference in the rate of high-school completion between sexes or does a medical test have a better true positive rate than an existing tool? Constructing [confidence intervals](https://en.wikipedia.org/wiki/Confidence_interval) for [binomial proportions](https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval) is statistically tricky because a binomial proportion's distribution is often unknown. Asymptotically this proportion will actually have a normal distribution, and this normal approximation is often used in practice. \n",
    "\n",
    "This post will provide analytic ways of calculating the sample size for binomial confidence intervals for both normal and more advanced methods.\n",
    "\n",
    "\n",
    "## Preliminaries\n",
    "\n",
    "To quickly establish some notation that will be used throughout the post: we are considering the proportion of successes in a binomial trial: $p=y / n$, where $y \\sim \\text{Binom}(\\pi, n)$. Therefore $E(p)=\\pi$ and $Var(p)=\\pi(1-\\pi)/n = \\sigma^2_\\pi$. Assymptotically it is known that $p$ can be transformed so that it is normally distributed: $z=(p - \\pi)/\\sigma_\\pi \\sim N(0,1)$. Suppose we measure the proportions from two different IID groups 1 and 2: $p_1$ and $p_2$, $E(p_i)=\\pi_i$, with $n_1$ and $n_2$ samples. If we want to establish whether group 1 has a higher proportion than group 2 will specify a null and alternative hypothesis as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "H_0 &: \\pi_1 \\leq \\pi_2 \\\\\n",
    "H_A &: \\pi_1 > \\pi_2, \\hspace{3mm} \\pi_1 - \\pi_2 = \\Delta > 0 \\\\\n",
    "z_0 &= \\frac{p_1 - p_2}{\\sigma_{\\pi_0}} \\\\\n",
    "\\sigma_{\\pi} &= \\frac{\\pi_1(1-\\pi_1)}{n_1} + \\frac{\\pi_2(1-\\pi_2)}{n_2} \\\\\n",
    "\\sigma_{\\pi_0} &= \\sigma_{\\pi} | H_0 = \\frac{\\pi_1(1-\\pi_1)}{n}(w_1 + w_2) \\\\\n",
    "n &= n_1+n_2, \\hspace{3mm} w_i = n / n_i\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Note that in the null I assume $\\pi_1=\\pi_2$ rather than $\\pi_1 < \\pi_2$, both of which conditions could be true under the null. However, the former case is the most conservative assumption for our subsequent power analysis and should be used.  Also note that the symbol $\\Phi$ refers to the standard normal CDF, which will be used throughout the post. The hat notation refers to a realization of the random variable so that $p_1$ is a random variable and $\\hat p_1$ is a realization of the proportion for group 1. If $z_0 > t_\\alpha$ we will reject the null, where $P(z_0 > t_\\alpha | H_0) = \\alpha$. The type-II error will be denoted as $\\beta$ so that $P(z_A > t_\\alpha | H_A) = 1-\\beta$ is the power.\n",
    "\n",
    "## Normal approximation approach (1)\n",
    "\n",
    "Assume that $n$ is large enough that we can use the z-score formula seen in the preliminaries. Then it is easy enough to derive an approximation for the power calculation as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "z_A = z | H_A &= \\frac{p_1 - p_2 - \\Delta}{\\sigma_{\\pi_A}} \\sim N(0,1) \\\\\n",
    "\\sigma_{\\pi_A} &= \\frac{\\pi_1(1-\\pi_1)}{n_1} + \\frac{(\\pi_1-\\Delta)(1-(\\pi_1-\\Delta))}{n_2} \\\\\n",
    "&= \\sigma_{\\pi_0} + \\epsilon, \\hspace{3mm} \\epsilon=\\frac{\\Delta(2\\pi_1-1)-\\Delta^2}{n_2}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Because $\\epsilon(\\Delta,\\pi_1,n_2)$ is $O(n_2^{-1})$ it is often ignored in the analysis since for large enough $n_2$ it is basically zero. If one sets $\\epsilon=0$, then there is a elegant closed-form solution to solving for a specific power:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P( z > t_\\alpha) &= P\\Bigg( \\frac{p_1 - p_2}{\\sigma_{\\pi_0}} > t_\\alpha \\Bigg) \\\\\n",
    "&= P\\Bigg( \\frac{p_1 - p_2}{\\sigma_{\\pi_0}}-\\frac{\\Delta}{\\sigma_{\\pi_0}}+\\frac{\\Delta}{\\sigma_{\\pi_0}} > t_\\alpha | H_A \\Bigg) \\\\\n",
    "&= P\\Bigg( z_A > t_\\alpha - \\frac{\\Delta}{\\sigma_{\\pi_0}} | H_A \\Bigg) \\\\\n",
    "1-\\beta &= 1 - \\Phi(t_\\alpha - \\Delta / \\sigma_{\\pi_0}) \\\\\n",
    "\\frac{n_1n_2}{n} &= \\frac{\\pi_1(1-\\pi_1)(\\Phi^{-1}_{1-\\beta} + t_\\alpha)^2}{\\Delta^2}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "If the two groups have the same sample size: $n_1 = n_2$, then the exact formula is:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "n^* &= 2\\cdot \\frac{\\pi_1(1-\\pi_1)(\\Phi^{-1}_{1-\\beta} + t_\\alpha)^2}{\\Delta^2} \\label{eq:simple1}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "As the simulation results show, this method does fairly well for a large $n$ and true $\\Delta$ that is small.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotnine\n",
    "from plotnine import *\n",
    "seed = 1234 # Use throughout post\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal approximation approach (2)\n",
    "\n",
    "If we want to either.... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "502.51256281407035"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nstar = 100\n",
    "n2 = 10000\n",
    "n2*n/(2*n2-nstar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arcsin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_seq = np.round(np.arange(0.01, 1, 0.01),2)\n",
    "n = 1000\n",
    "nsim = 2500\n",
    "np.random.seed(seed)\n",
    "df_arcsin = pd.concat([pd.DataFrame({'phat':[np.random.binomial(n,p)/n for z in range(nsim)],'p':p}) for p in p_seq])\n",
    "df_arcsin = df_arcsin.assign(ptrans= lambda x: np.arcsin(np.sqrt(x.phat)))\n",
    "df_arcsin_var = df_arcsin.groupby('p').ptrans.std().reset_index().rename(columns={'ptrans':'var_trans'})\n",
    "\n",
    "gg_arcsin = (ggplot(df_arcsin_var, aes(x='p',y='var_trans')) + theme_bw() + \n",
    "             geom_point() + \n",
    "             geom_hline(yintercept=np.sqrt(1/(4*n)),color='blue',linetype='--') + \n",
    "             labs(x='True proportion',y='Standard deviation of outcome') + \n",
    "             ggtitle('Variation in arcsin() transform'))\n",
    "gg_arcsin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "* * * \n",
    "\n",
    "### Footnotes\n",
    "\n",
    "[^1]: I discuss this phenomenon at length in this [post](http://www.erikdrysdale.com/winners_curse) and provide some methods to correct for lower-powered tests.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
